{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "01bb7c53-9f37-4b8e-a581-7c50e0eeb335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 295\n"
     ]
    }
   ],
   "source": [
    "from netCDF4 import Dataset\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_file(topology_file_path):\n",
    "    matched_df = pd.read_csv(topology_file_path)\n",
    "    return matched_df\n",
    "\n",
    "\n",
    "matched = glob.glob('/nas/cee-water/cjgleason/euro_data/euro_lisflood/Euro_sword_topology/*')\n",
    "\n",
    "cnt = 0\n",
    "for topology_file_path in matched:\n",
    "    print(cnt, 'of', len(matched))\n",
    "    cnt +=1\n",
    "    matched_df = load_file(topology_file_path)\n",
    "    # print(topology_file_path)\n",
    "    # loop through links\n",
    "    links = matched_df.link.unique()\n",
    "    \n",
    "    for l in links:\n",
    "        linked_df = matched_df[matched_df['link'] == l]\n",
    "        # print(linked_df)\n",
    "        break\n",
    "    break\n",
    "        \n",
    "#         #restart function\n",
    "#         # for sword_reach in linked_df.reach_id.unique():\n",
    "#         restart_paths = [os.path.exists(f'/nas/cee-water/cjgleason/travis/out_testing/{sword_reach}.nc') for sword_reach in linked_df.reach_id.unique()]\n",
    "#         # print(restart_paths)\n",
    "        \n",
    "#         if False in restart_paths:\n",
    "            \n",
    "\n",
    "#             # find and load netcdf\n",
    "\n",
    "#             basin = os.path.basename(topology_file_path).split('_')[0]\n",
    "\n",
    "\n",
    "#             nc_file_path = f'/nas/cee-water/cjgleason/travis/data/euro_swot_nc/{basin}_{l}_SWOT.nc'\n",
    "#             # print(nc_file_path)\n",
    "\n",
    "#             #be sure it exists in test set\n",
    "#             if os.path.exists(nc_file_path):\n",
    "#                 netcd = Dataset(nc_file_path, mode = 'r+', clobber=True)\n",
    "#             # except:\n",
    "#             #     break\n",
    "#             else:\n",
    "#                 break\n",
    "\n",
    "\n",
    "#             print(nc_file_path)\n",
    "#             var_width_csv = f'/nas/cee-water/cjgleason/yuta/laplace/data/euro_data/euro_variable_width/out/wfull_lisflood_dfull_sos/{basin}_{l}.csv'\n",
    "#             var_width_df = pd.read_csv(var_width_csv)\n",
    "\n",
    "\n",
    "\n",
    "#             # be sure there are varaible widths\n",
    "#             if len(var_width_df.variable_width.unique()) > 1:\n",
    "#                 var_widths = var_width_df['variable_width']\n",
    "#                 # print(var_widths)\n",
    "\n",
    "#                 # overwrite widths of netcdf\n",
    "#                 netcd['reach']['width'][:] = var_widths[1:(len(netcd['reach']['width'][:])+1)]\n",
    "                \n",
    "#                             # overwrite nodes\n",
    "#                 new_nodes = [var_widths[1:(len(netcd['reach']['width'][:])+1)] for i in range(len(netcd['node']['width'][:]))]\n",
    "\n",
    "#                 netcd['node']['width'][:] = new_nodes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#                 #check if there is more than one reach_id's\n",
    "#                 for sword_reach in linked_df.reach_id.unique():\n",
    "\n",
    "#                     shutil.copyfile(nc_file_path, f'/nas/cee-water/cjgleason/travis/out_testing/{sword_reach}.nc')\n",
    "#                 break\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1d9756f-f065-420e-a59f-d5b2ae69261b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    title: SWOT data for reach ID: 002_403\n",
      "    dimensions(sizes): nchar(7), nt(9362), nx(3)\n",
      "    variables(dimensions): int32 nt(nt), int32 nx(nx)\n",
      "    groups: reach, node\n"
     ]
    }
   ],
   "source": [
    "from netCDF4 import Dataset\n",
    "\n",
    "\n",
    "net = Dataset('/nas/cee-water/cjgleason/euro_data/netcdf_data/002_403_SWOT.nc')\n",
    "print(net)\n",
    "# print(net['node']['width'][:10])\n",
    "# print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f7f0631-a8c0-42b8-bbe8-9d39d0e089d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link fix - this is the one\n",
    "from netCDF4 import Dataset\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def load_file(topology_file_path):\n",
    "    matched_df = pd.read_csv(topology_file_path)\n",
    "    return matched_df\n",
    "\n",
    "\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "import subprocess as sp\n",
    "\n",
    "sword_path = '/nas/cee-water/cjgleason/travis/data/mnt/input/sword/eu_sword_v11.nc'\n",
    "sword = Dataset(sword_path)\n",
    "def find_reach_nx(sword):\n",
    "    reach_nxs = Counter(sword['nodes']['reach_id'][:])\n",
    "    return reach_nxs\n",
    "reach_nxs = find_reach_nx(sword)\n",
    "matched = glob.glob('/nas/cee-water/cjgleason/euro_data/euro_lisflood/Euro_sword_topology/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee71ef74-21e9-497f-8fa4-242e4ddb0644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link is 21303000131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/modules/apps/miniconda/4.8.3/envs/jupyterhub-stable/lib/python3.10/site-packages/numpy/ma/core.py:2826: UserWarning: Warning: converting a masked element to nan.\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nas/cee-water/cjgleason/travis/out_testing/21303000131.nc\n",
      "shorten\n",
      "shorten\n",
      "shorten\n",
      "shorten\n",
      "width 9862\n",
      "link is 24298000106\n",
      "/nas/cee-water/cjgleason/travis/out_testing/24298000106.nc\n",
      "shorten\n",
      "shorten\n",
      "shorten\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agg_var \u001b[38;5;129;01min\u001b[39;00m agg_var_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreach\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;66;03m# print(agg_var, 'ov')\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     target_nx \u001b[38;5;241m=\u001b[39m reach_nxs[\u001b[38;5;28mint\u001b[39m(l)]\n\u001b[0;32m--> 207\u001b[0m     \u001b[43moverwrite_variable\u001b[49m\u001b[43m(\u001b[49m\u001b[43magg_var_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magg_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetcd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_nx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36moverwrite_variable\u001b[0;34m(agg_var_dict, agg_var, netcd, target_nx)\u001b[0m\n\u001b[1;32m    197\u001b[0m netcd[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreach\u001b[39m\u001b[38;5;124m'\u001b[39m][agg_var][:] \u001b[38;5;241m=\u001b[39m agg_var_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreach\u001b[39m\u001b[38;5;124m'\u001b[39m][agg_var][:(\u001b[38;5;28mlen\u001b[39m(netcd[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreach\u001b[39m\u001b[38;5;124m'\u001b[39m][agg_var][:]))]\n\u001b[1;32m    198\u001b[0m new_nodes \u001b[38;5;241m=\u001b[39m [agg_var_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreach\u001b[39m\u001b[38;5;124m'\u001b[39m][agg_var][:(\u001b[38;5;28mlen\u001b[39m(netcd[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreach\u001b[39m\u001b[38;5;124m'\u001b[39m][agg_var][:]))] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(netcd[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode\u001b[39m\u001b[38;5;124m'\u001b[39m][agg_var][:]))]\n\u001b[0;32m--> 199\u001b[0m netcd[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode\u001b[39m\u001b[38;5;124m'\u001b[39m][agg_var][:] \u001b[38;5;241m=\u001b[39m new_nodes\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:5477\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Variable.__setitem__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:4550\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Variable.shape.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/netCDF4/utils.py:34\u001b[0m, in \u001b[0;36m_find_dim\u001b[0;34m(grp, dimname)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sortbylist\u001b[39m(A,B):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# sort one list (A) using the values from another list (B)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [A[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(A)), key\u001b[38;5;241m=\u001b[39mB\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m)]\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_find_dim\u001b[39m(grp, dimname):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# find Dimension instance given group and name.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# look in current group, and parents.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     group \u001b[38;5;241m=\u001b[39m grp\n\u001b[1;32m     38\u001b[0m     dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# reach_nxs[21303000131]\n",
    "\n",
    "\n",
    "# Link fix - this is the one\n",
    "from netCDF4 import Dataset\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def load_file(topology_file_path):\n",
    "    matched_df = pd.read_csv(topology_file_path)\n",
    "    return matched_df\n",
    "\n",
    "\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "import subprocess as sp\n",
    "\n",
    "sword_path = '/nas/cee-water/cjgleason/travis/data/mnt/input/sword/eu_sword_v11.nc'\n",
    "sword = Dataset(sword_path)\n",
    "def find_reach_nx(sword):\n",
    "    reach_nxs = Counter(sword['nodes']['reach_id'][:])\n",
    "    return reach_nxs\n",
    "reach_nxs = find_reach_nx(sword)\n",
    "matched = glob.glob('/nas/cee-water/cjgleason/euro_data/euro_lisflood/Euro_sword_topology/*')\n",
    "\n",
    "cnt = 0\n",
    "for topology_file_path in matched:\n",
    "    # print(cnt, 'of', len(matched))\n",
    "    cnt +=1\n",
    "    matched_df = load_file(topology_file_path)\n",
    "    # print(topology_file_path)\n",
    "    # loop through links\n",
    "    reach_ids = matched_df.reach_id.unique()\n",
    "\n",
    "    for l in reach_ids:\n",
    "        if not math.isnan(l):\n",
    "            print('link is', l)\n",
    "\n",
    "            linked_df = matched_df[matched_df['reach_id'] == l]\n",
    "\n",
    "\n",
    "\n",
    "            #find euro reachs associated with that reach_id\n",
    "\n",
    "            euro_links = linked_df.link.unique()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #         for euro_link in euro_links:\n",
    "\n",
    "\n",
    "    #             # load each variable width \n",
    "    #             basin = os.path.basename(topology_file_path).split('_')[0]\n",
    "\n",
    "    #             nc_file_path = f'/nas/cee-water/cjgleason/travis/data/euro_swot_nc/{basin}_{euro_link}_SWOT.nc'\n",
    "\n",
    "    #             #be sure it exists in test set\n",
    "    #             if os.path.exists(nc_file_path):\n",
    "    #                 netcd = Dataset(nc_file_path, mode = 'r+', clobber=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            agg_var_dict = {\n",
    "                'reach' : {\n",
    "                    'd_x_area': [], \n",
    "                    'slope2': [], \n",
    "                    'wse' :[],\n",
    "                    'width':[]\n",
    "                },\n",
    "\n",
    "                # 'node': {\n",
    "                #     'd_x_area': [], \n",
    "                #     'slope2': [], \n",
    "                #     'wse' :[],\n",
    "                #     'width':[]\n",
    "                # },\n",
    "            }\n",
    "\n",
    "            for euro_link in euro_links:\n",
    "\n",
    "                # load each variable width \n",
    "                basin = os.path.basename(topology_file_path).split('_')[0]\n",
    "\n",
    "                nc_file_path = f'/nas/cee-water/cjgleason/travis/data/euro_swot_nc/{basin}_{euro_link}_SWOT.nc'\n",
    "\n",
    "                var_width_csv = f'/nas/cee-water/cjgleason/yuta/laplace/data/euro_data/euro_variable_width/out/wfull_lisflood_dfull_sos/{basin}_{euro_link}.csv'\n",
    "                var_width_df = pd.read_csv(var_width_csv)\n",
    "\n",
    "                #be sure it exists in test set\n",
    "                if os.path.exists(nc_file_path):\n",
    "                    netcd = Dataset(nc_file_path, mode = 'r+', clobber=True)\n",
    "\n",
    "                    for level in agg_var_dict.keys():\n",
    "\n",
    "                        for agg_var in agg_var_dict[level].keys():\n",
    "\n",
    "                            # load variable widths for each\n",
    "                            if agg_var == 'width':\n",
    "                                if len(var_width_df.variable_width.unique()) > 1:\n",
    "\n",
    "                                    var_values = list(var_width_df['variable_width'])\n",
    "                                else:\n",
    "                                    var_values = []\n",
    "\n",
    "                            else: \n",
    "                                var_values = netcd[level][agg_var][:]\n",
    "\n",
    "                            # check if this is the first time we are adding values\n",
    "                            if len(agg_var_dict[level][agg_var]) == 0:\n",
    "                                agg_var_dict[level][agg_var] = [[a_value] for a_value in var_values]\n",
    "\n",
    "                            # make a sub list elementwize\n",
    "                            else:\n",
    "                                # print(level, agg_var, var_values[0])\n",
    "                                # try:\n",
    "                                #     print(len(var_values), 'by', len(var_values[0]))\n",
    "                                # except:\n",
    "                                #     continue\n",
    "\n",
    "\n",
    "\n",
    "                                # therea are different nubmers of nodes that we are trying to aggregate\n",
    "                                # email out to see how we should handle it\n",
    "                                # print(nc_file_path)\n",
    "                                # print(agg_var, len(agg_var_dict[level][agg_var]), 'by', len(agg_var_dict[level][agg_var][0]))\n",
    "\n",
    "                                for index_v, a_value in enumerate(var_values):\n",
    "                                    agg_var_dict[level][agg_var][index_v].append(a_value)\n",
    "\n",
    "\n",
    "\n",
    "            # average their data together and store \n",
    "\n",
    "            for level in agg_var_dict.keys():\n",
    "                for agg_var in agg_var_dict[level].keys():\n",
    "\n",
    "                    for index_v, a_value in enumerate(agg_var_dict[level][agg_var]):\n",
    "\n",
    "                        agg_var_dict[level][agg_var][index_v] = np.ma.asarray(agg_var_dict[level][agg_var][index_v]).mean(axis=0)\n",
    "\n",
    "\n",
    "\n",
    "            # use last nc_file_path to do the sword reach nc write out\n",
    "\n",
    "            shutil.copyfile(nc_file_path, f'/nas/cee-water/cjgleason/travis/out_testing/{l}.nc')\n",
    "\n",
    "            # open new nc file\n",
    "            new_fp = f'/nas/cee-water/cjgleason/travis/out_testing/{l}.nc'\n",
    "            netcd = Dataset(new_fp, mode = 'r+', clobber=True)\n",
    "\n",
    "            print(f'/nas/cee-water/cjgleason/travis/out_testing/{l}.nc')\n",
    "            \n",
    "            def overwrite_variable(agg_var_dict, agg_var, netcd, target_nx):\n",
    "                \n",
    "                # resize_dims\n",
    "                if len(netcd['node'][agg_var][:]) > target_nx:\n",
    "                    # resize_cmd = ['ncks', '-d', f'nx,0,{len(netcd['node'][agg_var][:])-1}', '-d', f'nx,0,{\n",
    "                    # shrink_cmd = ['ncks', '-d', f'nx,0,{target_nx-1}', new_fp, new_fp]\n",
    "                    # sp.run(shrink_cmd)\n",
    "                    print('shorten')\n",
    "                \n",
    "                else:\n",
    "                    print('lengthen')\n",
    "                    \n",
    "                \n",
    "                # overwrite widths of netcdf\n",
    "                # we have to check if width has values because if all the var width dfs associated with this reach had nan values\n",
    "                # we want to keep constant the ones it has now\n",
    "                if agg_var == 'width':\n",
    "                    if len(agg_var_dict['reach']['width']) != 0:\n",
    "                        print(agg_var, len(agg_var_dict['reach'][agg_var]))\n",
    "                        # we move our width selection up by 1 becaues the starting withs are nan values\n",
    "                        # in this step we are also only selecting nt number of widths\n",
    "                        netcd['reach'][agg_var][:] = agg_var_dict['reach'][agg_var][1:(len(netcd['reach'][agg_var][:])+1)]\n",
    "                        new_nodes = [agg_var_dict['reach'][agg_var][1:(len(netcd['reach'][agg_var][:])+1)] for i in range(len(netcd['node'][agg_var][:]))]\n",
    "                        netcd['node'][agg_var][:] = new_nodes\n",
    "\n",
    "                else:\n",
    "                    netcd['reach'][agg_var][:] = agg_var_dict['reach'][agg_var][:(len(netcd['reach'][agg_var][:]))]\n",
    "                    new_nodes = [agg_var_dict['reach'][agg_var][:(len(netcd['reach'][agg_var][:]))] for i in range(len(netcd['node'][agg_var][:]))]\n",
    "                    netcd['node'][agg_var][:] = new_nodes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            for agg_var in agg_var_dict['reach'].keys():\n",
    "                # print(agg_var, 'ov')\n",
    "                target_nx = reach_nxs[int(l)]\n",
    "                overwrite_variable(agg_var_dict, agg_var, netcd, target_nx)\n",
    "            break\n",
    "        \n",
    "        \n",
    "        \n",
    "        #----------------------------------------------------------------------------------------\n",
    "        \n",
    "#         #restart function\n",
    "#         # for sword_reach in linked_df.reach_id.unique():\n",
    "#         restart_paths = [os.path.exists(f'/nas/cee-water/cjgleason/travis/out_testing/{sword_reach}.nc') for sword_reach in linked_df.reach_id.unique()]\n",
    "#         # print(restart_paths)\n",
    "        \n",
    "#         if False in restart_paths:\n",
    "            \n",
    "\n",
    "#             # find and load netcdf\n",
    "\n",
    "#             basin = os.path.basename(topology_file_path).split('_')[0]\n",
    "\n",
    "\n",
    "#             nc_file_path = f'/nas/cee-water/cjgleason/travis/data/euro_swot_nc/{basin}_{l}_SWOT.nc'\n",
    "#             # print(nc_file_path)\n",
    "\n",
    "#             #be sure it exists in test set\n",
    "#             if os.path.exists(nc_file_path):\n",
    "#                 netcd = Dataset(nc_file_path, mode = 'r+', clobber=True)\n",
    "#             # except:\n",
    "#             #     break\n",
    "#             else:\n",
    "#                 break\n",
    "\n",
    "\n",
    "#             print(nc_file_path)\n",
    "#             var_width_csv = f'/nas/cee-water/cjgleason/yuta/laplace/data/euro_data/euro_variable_width/out/wfull_lisflood_dfull_sos/{basin}_{l}.csv'\n",
    "#             var_width_df = pd.read_csv(var_width_csv)\n",
    "\n",
    "\n",
    "\n",
    "#             # be sure there are varaible widths\n",
    "#             if len(var_width_df.variable_width.unique()) > 1:\n",
    "#                 var_widths = var_width_df['variable_width']\n",
    "#                 # print(var_widths)\n",
    "\n",
    "#                 # overwrite widths of netcdf\n",
    "#                 netcd['reach']['width'][:] = var_widths[1:(len(netcd['reach']['width'][:])+1)]\n",
    "                \n",
    "#                             # overwrite nodes\n",
    "#                 new_nodes = [var_widths[1:(len(netcd['reach']['width'][:])+1)] for i in range(len(netcd['node']['width'][:]))]\n",
    "\n",
    "#                 netcd['node']['width'][:] = new_nodes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#                 #check if there is more than one reach_id's\n",
    "#                 for sword_reach in linked_df.reach_id.unique():\n",
    "\n",
    "#                     shutil.copyfile(nc_file_path, f'/nas/cee-water/cjgleason/travis/out_testing/{sword_reach}.nc')\n",
    "#                 break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb97c380-61ef-45e2-a4c9-bb2e5a2be756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "netcd = Dataset('/nas/cee-water/cjgleason/travis/out_testing/21303000131.nc', mode = 'r+', clobber=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fde52429-4b5c-4e28-87f7-ccc978e58505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Dataset'>\n",
       "root group (NETCDF4 data model, file format HDF5):\n",
       "    title: SWOT data for reach ID: 646_917\n",
       "    history: Fri Jan  6 21:03:21 2023: ncks -d nx,0,93 /nas/cee-water/cjgleason/travis/out_testing/21303000131.nc /nas/cee-water/cjgleason/travis/out_testing/21303000131.nc\n",
       "Fri Jan  6 21:03:19 2023: ncks -d nx,0,93 /nas/cee-water/cjgleason/travis/out_testing/21303000131.nc /nas/cee-water/cjgleason/travis/out_testing/21303000131.nc\n",
       "Fri Jan  6 21:03:18 2023: ncks -d nx,0,93 /nas/cee-water/cjgleason/travis/out_testing/21303000131.nc /nas/cee-water/cjgleason/travis/out_testing/21303000131.nc\n",
       "Fri Jan  6 21:03:15 2023: ncks -d nx,0,93 /nas/cee-water/cjgleason/travis/out_testing/21303000131.nc /nas/cee-water/cjgleason/travis/out_testing/21303000131.nc\n",
       "    NCO: netCDF Operators version 5.1.3 (Homepage = http://nco.sf.net, Code = http://github.com/nco/nco)\n",
       "    dimensions(sizes): nx(94), nt(9362), nchar(7)\n",
       "    variables(dimensions): int32 nt(nt), int32 nx(nx)\n",
       "    groups: node, reach"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2761293a-d016-4b75-916a-cf7d4b9488a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# netcd.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "735f6fa2-36d9-4e8d-80c7-40d441cac154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.39651649 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649\n",
      " 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649\n",
      " 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649\n",
      " 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649\n",
      " 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649\n",
      " 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649\n",
      " 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649\n",
      " 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649\n",
      " 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649\n",
      " 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649\n",
      " 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649\n",
      " 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649\n",
      " 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649\n",
      " 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649\n",
      " 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649 9.39651649\n",
      " 9.39651649 9.39651649 9.39651649 9.39651649]\n",
      "9.396516486830777\n"
     ]
    }
   ],
   "source": [
    "print(netcd['node']['d_x_area'][:,0])\n",
    "print(netcd['reach']['d_x_area'][:][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bd250ef-ac75-4a6f-9b9e-0980d16f2f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Dimension'>: name = 'new_nx', size = 20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to figure out how to change the nx dimension of this file\n",
    "\n",
    "\n",
    "# netcd\n",
    "\n",
    "target_dim_size = 20\n",
    "\n",
    "netcd.createDimension('new_nx',20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ac51d3d-e125-46d6-937b-f43d29e4d163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Dataset'>\n",
       "root group (NETCDF4 data model, file format HDF5):\n",
       "    title: SWOT data for reach ID: 646_917\n",
       "    dimensions(sizes): nchar(7), nt(9362), nx(122), new_nx(20)\n",
       "    variables(dimensions): int32 nt(nt), int32 nx(nx)\n",
       "    groups: reach, node"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55439179-1fe6-4f49-a87d-6ae69a598344",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "NetCDF: String match to name in use",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslope2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwse\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m----> 2\u001b[0m     var \u001b[38;5;241m=\u001b[39m \u001b[43mnetcd\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnew_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mint32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnew_nx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(netcd[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode\u001b[39m\u001b[38;5;124m'\u001b[39m][i])\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2962\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.createVariable\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:4193\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Variable.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2028\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: NetCDF: String match to name in use"
     ]
    }
   ],
   "source": [
    "for i in ['slope2', 'width', 'wse']:\n",
    "    var = netcd['node'].createVariable(f'new_{i}', 'int32', ('nt','new_nx'))\n",
    "    print(netcd['node'][i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1df7e343-7c2d-4f08-adcc-a9b1cdb7ac8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Group'>\n",
      "group /node:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): |S1 reach_id(nchar), float64 d_x_area(nx, nt), float64 slope2(nx, nt), float64 width(nx, nt), float64 wse(nx, nt), int32 new_slope2(new_nx), int32 new_width(new_nx), int32 new_wse(new_nx)\n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    "print(netcd['node'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a560fa7d-e836-4bca-87f3-d4c05b314081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027a40dc-7be7-471c-81ec-3749895012e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfb43a7-cc15-4bb7-81a5-5e389b2eac59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c93646c-e7e3-44bf-a024-802d7ecafc87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93837627-3fbb-49ff-9f5d-52842d721c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0cd7539-59a8-4bd6-81e9-6513fe2efbb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find nx given a reach\n",
    "\n",
    "sword_path = '/nas/cee-water/cjgleason/travis/data/mnt/input/sword/eu_sword_v11.nc'\n",
    "from netCDF4 import Dataset\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "sword = Dataset(sword_path)\n",
    "def find_reach_nx(sword):\n",
    "    reach_nxs = Counter(sword['nodes']['reach_id'][:])\n",
    "    return reach_nxs\n",
    "    \n",
    "reach_nxs = find_reach_nx(sword)\n",
    "\n",
    "reach_nxs[21303000131]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13bdc2f0-7b5d-44a0-842b-1930a6346429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "# find nx given a reach\n",
    "\n",
    "sword_path = '/nas/cee-water/cjgleason/travis/data/mnt/input/sword/eu_sword_v11.nc'\n",
    "from netCDF4 import Dataset\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "sword = Dataset(sword_path)\n",
    "def find_reach_nx(sword):\n",
    "    reach_nxs = Counter(sword['nodes']['reach_id'][:])\n",
    "    return reach_nxs\n",
    "    \n",
    "reach_nxs = find_reach_nx(sword)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# all_files = glob.glob('/nas/cee-water/cjgleason/travis/out_testing/*')\n",
    "\n",
    "# a_file = random.choice(all_files)\n",
    "\n",
    "# num = os.path.basename(a_file.replace('.nc',''))\n",
    "# print(num)\n",
    "\n",
    "# netcd = Dataset(a_file, mode = 'r+', clobber=True)\n",
    "\n",
    "# print(netcd.dimensions['nx'].size, reach_nxs[num])\n",
    "\n",
    "# netcd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89a04128-b65d-4edb-85d5-8869ceeda581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22160200281\n",
      "81 81\n"
     ]
    }
   ],
   "source": [
    "all_files = glob.glob('/nas/cee-water/cjgleason/travis/out_testing/*')\n",
    "\n",
    "a_file = random.choice(all_files)\n",
    "\n",
    "num = os.path.basename(a_file.replace('.nc',''))\n",
    "print(num)\n",
    "\n",
    "netcd = Dataset(a_file, mode = 'r+', clobber=True)\n",
    "print(netcd.dimensions['nx'].size, reach_nxs[int(num)])\n",
    "\n",
    "netcd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73d432ea-cd6d-4028-8344-22f2873548aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test and see if they are ever less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0685d114-0e18-4899-9edb-4b2477913dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4831c801-a665-4a16-926f-256d8f7cd68a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac01236-2744-4b7e-961b-4bfa1b924a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fd6ecc-8a16-49a5-b129-2b255658cc7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a44e8ef4-255f-4595-8d1f-7120a1f2289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# euro node id creation\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c768441e-6f08-47c4-b8bf-25d396063872",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob('./out_testing/*.nc')\n",
    "all_ids = [os.path.basename(i.replace('.nc','')) for i in all_files]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5058c9a-c016-44a5-aa9d-474b27e55f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['reach_id'])\n",
    "df['reach_id'] = all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed9bf410-0813-4688-809c-15c40a3d59b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('euro_data_reach_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a1856f-c8a5-4823-b914-8c81ce6a2d52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (4.8.3-jupyterhub-stable) *",
   "language": "python",
   "name": "conda-env-4.8.3-jupyterhub-stable-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
